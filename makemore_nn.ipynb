{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EIVd3xrBoUpAg_1RH-REi6TuTQgdVyfk",
      "authorship_tag": "ABX9TyMbFAiVR4u1i9JoYaom3wiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashu-0/nn-zero-to-hero/blob/main/makemore_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('/content/drive/MyDrive/makemore-nn/names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "eV547qg2oAhN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))   # 26 alphabets\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}    # stoi => string to integers\n",
        "stoi['.'] = 0                                 # considering single special char only\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "izVrofipoaSV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_8hnYXo1oJpc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WOHUfR4mLil",
        "outputId": "8a86d0f9-45d4-4e64-bf19-e34e96943127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". e\n",
            "e m\n",
            "m m\n",
            "m a\n",
            "a .\n"
          ]
        }
      ],
      "source": [
        "# create the training set of all the bigrams(x,y)\n",
        "xs, ys = [], []                     # xs => inputs, ys => labels\n",
        "\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    print(ch1,ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'inputs: {xs}')\n",
        "print(f'labels: {ys}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg9X8y_SnS0X",
        "outputId": "3721f71f-a44b-450c-b82e-c61a73dc5d0d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([ 0,  5, 13, 13,  1])\n",
            "labels: tensor([ 5, 13, 13,  1,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# difference between torch.Tensor and torch.tensor\n",
        "\n",
        "# torch.tensor infers the dtype automatically, whereas torch.Tensor returns float dtype\n",
        "# therfore use torch.tensor :P"
      ],
      "metadata": {
        "id": "AU5QTfKYohrG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding the input array\n",
        "\n",
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes = 27).float()                   # type casting it to float\n",
        "xenc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSVmXKnUptbL",
        "outputId": "ae785ca8-181e-47dc-e2c6-167e9c8ec618"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm1Hg7OMq5gR",
        "outputId": "3c76f9aa-f307-46d9-9b72-369c1740f8d7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(xenc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "s1JIkHBhrDAs",
        "outputId": "75107b2a-26c2-4a99-cfa6-689213e0decb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x788fc7d20970>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc.dtype       # while plugging numbers into neural nets we don't want them to be integers\n",
        "                 # we want them to be floating points"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KysrM3DYrLlI",
        "outputId": "5d6b899f-997f-46ef-c891-9ca99320d7b2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "\n",
        "W = torch.randn((27,27))                 # randn gives numbers from normal distribution\n",
        "xenc @ W                                # matrix multiplication  (5,27) @ (27,1)  => for one neuron"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xo7bcr8rXCH",
        "outputId": "f8609956-2cea-4391-d25d-cd63134a9805"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0555,  0.0429, -0.4218,  0.6101, -0.3684, -0.1366, -1.0152, -0.9019,\n",
              "          0.7420, -0.0217, -0.0489, -0.6191, -0.6020,  1.1014,  0.4021, -0.4315,\n",
              "          2.4259, -0.1193,  0.1331,  0.0634, -1.4446,  1.8609, -0.4070, -1.3823,\n",
              "         -1.2379, -0.4688,  0.3629],\n",
              "        [ 0.1954,  0.3923, -2.0068, -0.1483, -1.3904,  0.0785,  0.5249,  1.2737,\n",
              "         -0.3701, -1.0550, -0.2795,  1.5128, -2.5376,  0.9070, -1.2447, -0.4247,\n",
              "         -1.0011, -1.5927,  0.2279, -1.7064, -0.3240, -0.4534,  0.4569, -2.9764,\n",
              "          0.1176, -0.2666,  2.0917],\n",
              "        [ 0.0771, -0.6168, -0.6316,  0.2126, -2.9696,  1.0404,  0.0844, -0.0500,\n",
              "          0.4307,  2.5742, -1.7874,  1.3947, -0.9202,  1.6495,  1.2421, -0.4967,\n",
              "         -0.1198, -1.2327, -1.8776, -0.5693, -1.0862,  0.5555, -0.4151, -0.4208,\n",
              "          0.0478, -1.0027,  1.2454],\n",
              "        [ 0.0771, -0.6168, -0.6316,  0.2126, -2.9696,  1.0404,  0.0844, -0.0500,\n",
              "          0.4307,  2.5742, -1.7874,  1.3947, -0.9202,  1.6495,  1.2421, -0.4967,\n",
              "         -0.1198, -1.2327, -1.8776, -0.5693, -1.0862,  0.5555, -0.4151, -0.4208,\n",
              "          0.0478, -1.0027,  1.2454],\n",
              "        [ 0.0529, -0.8151, -1.7850,  1.4016, -0.7293,  0.1736,  0.8221, -0.4626,\n",
              "          1.4637,  0.2316,  0.2484, -0.5118, -0.9745,  1.1852, -1.7963,  0.4961,\n",
              "         -0.0667, -0.6611, -2.5598,  0.2737,  1.4437, -0.4480, -0.0941,  1.0317,\n",
              "          0.8434,  0.1482, -0.6690]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = xenc @ W    # log-counts also called as logits\n",
        "counts = logits.exp()      # equivalent to N array of counts in bigram model\n",
        "probs = counts / counts.sum(1, keepdims = True)     # prob are counts normalised\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf448yWNvx6O",
        "outputId": "449d5047-4186-4354-a02c-e49207a5d4a7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0228, 0.0252, 0.0158, 0.0444, 0.0167, 0.0211, 0.0087, 0.0098, 0.0507,\n",
              "         0.0236, 0.0230, 0.0130, 0.0132, 0.0726, 0.0361, 0.0157, 0.2730, 0.0214,\n",
              "         0.0276, 0.0257, 0.0057, 0.1552, 0.0161, 0.0061, 0.0070, 0.0151, 0.0347],\n",
              "        [0.0346, 0.0422, 0.0038, 0.0246, 0.0071, 0.0308, 0.0481, 0.1018, 0.0197,\n",
              "         0.0099, 0.0215, 0.1293, 0.0023, 0.0706, 0.0082, 0.0186, 0.0105, 0.0058,\n",
              "         0.0358, 0.0052, 0.0206, 0.0181, 0.0450, 0.0015, 0.0320, 0.0218, 0.2307],\n",
              "        [0.0230, 0.0115, 0.0113, 0.0263, 0.0011, 0.0602, 0.0231, 0.0202, 0.0327,\n",
              "         0.2790, 0.0036, 0.0858, 0.0085, 0.1107, 0.0736, 0.0129, 0.0189, 0.0062,\n",
              "         0.0033, 0.0120, 0.0072, 0.0371, 0.0140, 0.0140, 0.0223, 0.0078, 0.0739],\n",
              "        [0.0230, 0.0115, 0.0113, 0.0263, 0.0011, 0.0602, 0.0231, 0.0202, 0.0327,\n",
              "         0.2790, 0.0036, 0.0858, 0.0085, 0.1107, 0.0736, 0.0129, 0.0189, 0.0062,\n",
              "         0.0033, 0.0120, 0.0072, 0.0371, 0.0140, 0.0140, 0.0223, 0.0078, 0.0739],\n",
              "        [0.0273, 0.0114, 0.0043, 0.1051, 0.0125, 0.0308, 0.0589, 0.0163, 0.1118,\n",
              "         0.0326, 0.0332, 0.0155, 0.0098, 0.0846, 0.0043, 0.0425, 0.0242, 0.0134,\n",
              "         0.0020, 0.0340, 0.1096, 0.0165, 0.0235, 0.0726, 0.0601, 0.0300, 0.0133]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_ouRlx3wZXo",
        "outputId": "a91754c5-457b-4d25-e65c-2b792c7d57e2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5A4GBaAwenp",
        "outputId": "b013e9f0-816e-4bef-8332-5bf8464c24bc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0228, 0.0252, 0.0158, 0.0444, 0.0167, 0.0211, 0.0087, 0.0098, 0.0507,\n",
              "        0.0236, 0.0230, 0.0130, 0.0132, 0.0726, 0.0361, 0.0157, 0.2730, 0.0214,\n",
              "        0.0276, 0.0257, 0.0057, 0.1552, 0.0161, 0.0061, 0.0070, 0.0151, 0.0347])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for all 27 neurons\n",
        "# (5,27) @ (27,27) -> (5,27)\n",
        "\n",
        "# (xenc @ W)[3,13]                     # gives the firing rate of the 13th neuron looking at the 3rd input"
      ],
      "metadata": {
        "id": "C2uyC-dlsPh9"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (xenc[3] * W[:,13]).sum()"
      ],
      "metadata": {
        "id": "vUHy1UqRtwAi"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary =>>>>>>>>>>>>>>>>>>>"
      ],
      "metadata": {
        "id": "kDkVjWGSuJJ4"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs  # imputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTNLchoMWHgv",
        "outputId": "ec642021-ed42-4610-c8f3-9227cf085fd0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys  #labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUNtqjmWWSej",
        "outputId": "b58edfb6-4fe8-4146-fe7f-65cfad0cbb07"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize 27 neurons' weights each neuron recieves 27 inputs\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27,27), generator = g)"
      ],
      "metadata": {
        "id": "A4h1v0CiWUDh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = F.one_hot(xs, num_classes=27).float()       # encode input to one hot representation\n",
        "logits = xenc @ W    # predict log-counts\n",
        "counts = logits.exp()   # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims = True)    # normalise these counts to get probabilities for next char\n",
        "\n",
        "# softmax => last two lines combined are called softmax\n",
        "# thsi is the forward pass"
      ],
      "metadata": {
        "id": "4sbRDANPWn6I"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXOrxNphXyN9",
        "outputId": "e1b3d3af-78cf-4a00-b8e0-b404d6d66eee"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCwUwUwRX1BH",
        "outputId": "70c57f7c-61c1-4c85-8c0e-123ac1c68272"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
              "         0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
              "         0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459],\n",
              "        [0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
              "         0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
              "         0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472],\n",
              "        [0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
              "         0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
              "         0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
              "        [0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
              "         0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
              "         0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
              "        [0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
              "         0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
              "         0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarizing how well this network works on the one word \"emma\"\n",
        "\n",
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  # i-th bigram\n",
        "  x = xs[i].item()   # input char index\n",
        "  y = ys[i].item()   # label char index\n",
        "\n",
        "  print('----------------')\n",
        "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probalities from the neral nets:', probs[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i,y]\n",
        "  print('probability assigned by the neural net to be the correct charcter: ',p.item())\n",
        "  logp= torch.log(p)\n",
        "  print('log liklihood: ', logp.item())\n",
        "  nll = -logp\n",
        "  print('-ve log likelihood: ', nll.item())\n",
        "  nlls[i] =nll\n",
        "\n",
        "print('================')\n",
        "print('avg -ve log likelihood, i.e. loss= ' , nlls.mean().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceq4OZOKYxxX",
        "outputId": "64e80151-6bbb-41a8-9bb3-293241126608"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------\n",
            "bigram example 1: .e (indexes 0,5)\n",
            "input to the neural net: 0\n",
            "output probalities from the neral nets: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
            "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
            "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
            "label (actual next character): 5\n",
            "probability assigned by the neural net to be the correct charcter:  0.01228625513613224\n",
            "log liklihood:  -4.399273872375488\n",
            "-ve log likelihood:  4.399273872375488\n",
            "----------------\n",
            "bigram example 2: em (indexes 5,13)\n",
            "input to the neural net: 5\n",
            "output probalities from the neral nets: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
            "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
            "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
            "label (actual next character): 13\n",
            "probability assigned by the neural net to be the correct charcter:  0.018050700426101685\n",
            "log liklihood:  -4.014570713043213\n",
            "-ve log likelihood:  4.014570713043213\n",
            "----------------\n",
            "bigram example 3: mm (indexes 13,13)\n",
            "input to the neural net: 13\n",
            "output probalities from the neral nets: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
            "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
            "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
            "label (actual next character): 13\n",
            "probability assigned by the neural net to be the correct charcter:  0.026691533625125885\n",
            "log liklihood:  -3.623408794403076\n",
            "-ve log likelihood:  3.623408794403076\n",
            "----------------\n",
            "bigram example 4: ma (indexes 13,1)\n",
            "input to the neural net: 13\n",
            "output probalities from the neral nets: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
            "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
            "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
            "label (actual next character): 1\n",
            "probability assigned by the neural net to be the correct charcter:  0.07367686182260513\n",
            "log liklihood:  -2.6080665588378906\n",
            "-ve log likelihood:  2.6080665588378906\n",
            "----------------\n",
            "bigram example 5: a. (indexes 1,0)\n",
            "input to the neural net: 1\n",
            "output probalities from the neral nets: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
            "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
            "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
            "label (actual next character): 0\n",
            "probability assigned by the neural net to be the correct charcter:  0.014977526850998402\n",
            "log liklihood:  -4.201204299926758\n",
            "-ve log likelihood:  4.201204299926758\n",
            "================\n",
            "avg -ve log likelihood, i.e. loss=  3.7693049907684326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ Optimization ---------\n",
        "# optimizing the weights W like we did in micrograd"
      ],
      "metadata": {
        "id": "BsEfK-YXbuhg"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GenWwaiWeuN0",
        "outputId": "477a64a4-79af-48df-c5c5-c4ee23deb8d3"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MtT2G88evlR",
        "outputId": "734ace8f-6e81-4a0f-8a9c-cbf378b260dd"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize 27 neurons weights, each neuron recieves 27 inputs\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27,27), generator = g, requires_grad= True)"
      ],
      "metadata": {
        "id": "I_O3jSTUev-A"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "\n",
        "xenc= F.one_hot(xs,num_classes = 27).float()\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts/ counts.sum(1, keepdims = True)\n",
        "loss = - probs[torch.arange(5), ys].log().mean()"
      ],
      "metadata": {
        "id": "u8wNO3TvfJoD"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probs[0,5], probs[1,13], probs[2,13], probs[3,1], probs[4,0]\n",
        "#  a better way to do this in pytorch"
      ],
      "metadata": {
        "id": "Mxw8sU_tfp3N"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss = - probs[torch.arange(5), ys].log().mean()  # avg negative log likelihood using vectorized form\n",
        "# loss"
      ],
      "metadata": {
        "id": "ivlFvkHQgDQ6"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK6HuRWglCqp",
        "outputId": "1562aa00-d2fa-4f37-b09e-7a74ed4299a0"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.6892, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward pass\n",
        "W.grad = None   # setting gradient to zero\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "QaO6_xOkgMwN"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updating\n",
        "\n",
        "W.data += -0.1 * W.grad"
      ],
      "metadata": {
        "id": "uXXwMhoejBPr"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set W.grad = 0 --> update W --> forward pass --> calculate loss --> set W.grad = 0 --> update W and the cycle goes on\n",
        "# this is not but gradient descent algorithm"
      ],
      "metadata": {
        "id": "d3W786H6kIwG"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *************!!!!OPTIMIZATION!!!!! from scratch***************"
      ],
      "metadata": {
        "id": "AwnVA8abmEWU"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dataset\n",
        "xs, ys = [],[]\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi [ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_43iS77m4dR",
        "outputId": "6e80db1f-b477-4799-90a4-baa2d21faad0"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the network\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27,27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "hNAoJd-uohDB"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding regularization term (or loss)\n",
        "(W**2).mean()\n",
        " # this term tries to make all w's to be zero bcoz if w aren't zero you feel a loss\n",
        " # it's like adding a spring force or gravity force that pushes w to be zero"
      ],
      "metadata": {
        "id": "ftqryWprvxEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n",
        "\n",
        "for k in range(100):\n",
        "\n",
        "  # forward pass\n",
        "  xenc= F.one_hot(xs,num_classes = 27).float()\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts/ counts.sum(1, keepdims = True)\n",
        "  loss = - probs[torch.arange(num), ys].log().mean() + 0.01*((W**2).mean())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None   # setting gradient to zero\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad   # learning rate = 0.1 => 1 => 5 => 10 => 30 => 50\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxpvuYUEo3OH",
        "outputId": "f2d29cd2-b267-4cfe-ab60-13a32611f709"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4812512397766113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally !!!!!!!!! sample fro the 'neural-net model'\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    # ---------\n",
        "    # BEFORE:\n",
        "    # p = P[ix]\n",
        "    # ---------\n",
        "    # NOW:\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    p = counts /counts.sum(1, keepdims = True)\n",
        "    # ---------\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix ==0:\n",
        "      break\n",
        "  print(''.join(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk5AgF20paBA",
        "outputId": "92fc056a-2d9e-46fa-d595-abfc6154cd7f"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "janasah.\n",
            "p.\n",
            "cfay.\n",
            "a.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the result is same as that in manual bigram model (refer the makemore-bigram.ipynb notebook)\n",
        "\n"
      ],
      "metadata": {
        "id": "F-XspgZfyhEr"
      },
      "execution_count": 239,
      "outputs": []
    }
  ]
}